# Makefile

# Run ``make`` to execute pipeline
# Run ``make clean`` to delete data files

###
# Variables section
###

# List of data_sets to parse
data_sets := champion item
data := dragontail
lore_data_url :=  https://lol.fandom.com/wiki/

# Paths
csv_path := csv
src_path := src


# URLs and programme codes to get data from
YEAR := 2021
VERSION := 11.22.1
BASE_URL := "https://ddragon.leagueoflegends.com/cdn/dragontail-"
dragon_tail_URL := $(BASE_URL)$(VERSION).tgz
dragontail_version := $(data)$(VERSION)


###
# Rules section
###


# Starting target rule 'all'
# Processes all data_sets defined
all: data_sets_csv charts
	echo "Processed all data sets and made charts of their data"


# Retrieves dragontail data from official website
$(dragontail_version).tgz:
	curl $(dragon_tail_URL) > $(dragontail_version).tgz
	echo "Downloaded '$(dragontail_version)'.tgz file"


# Unzips dragontail data
$(dragontail_version): $(dragontail_version).tgz
	tar zxvf $(dragontail_version).tgz > $(dragontail_version)
	echo "Unziped '$(dragontail_version)'.tgz to folder"


# Convert JSON data_sets into CSV using python pandas and save them in csv folder
champions_to_csv: $(dragontail_version)
	python $(src_path)/json_to_csv.py $(dragontail_version)/$(VERSION)/data/en_US/champion.json csv_path/champions.csv
	echo "Converted champion.json to csv and stored it in folder "$(csv_path)


items.csv: $(dragontail_version)
	python $(src_path)/json_to_csv.py $(dragontail_version)/$(VERSION)/data/en_US/item.json csv_path/items.csv
	echo "Converted item.json to csv and stored it in folder "$(csv_path)


# Reorganizing csv columns for champion (skins, spells) and removing missing rows using python.
# This step is required because data was all spread through rows and columns instead of being all the data in each row (further explained in report)
champions_organize_col: champions_to_csv
	python $(src_path)/organize_some_cols_to_rows.py csv_path/champions.csv
	echo "Organized skins and spells rows properly and cleaned empty rows"


# Scrap lore from unofficial website using python since lore on dragontail data set was incomplete and append to champions csv
champions_with_lore : champions_organize_col
	python $(src_path)/scrap.py csv_path/champions.csv csv_path/champions.csv csv_path/champions.csv $(lore_data_url)
	echo "Scraped complete lore for each champion from '$(lore_data_url)'"


# Use NER (Name Entity Recognition) to retrieve entities (persons, locations, nationalities and events) from the lore of each character (labels of new columns explained in report)
champions.csv : champions_with_lore
	python $(src_path)/lore_ner.py csv_path/champions.csv csv_path/champions.csv
	echo "NER completed for the lore of each champion and stored in champions.csv"


data_sets_csv: champions.csv items.csv

# Characterize data by making charts about data and storing them in charts folder
charts: data_sets_csv
	python $(src_path)/make_charts.py csv_path/champions.csv csv_path/items.csv
	echo "Created charts for champions and items data"



# EOF
